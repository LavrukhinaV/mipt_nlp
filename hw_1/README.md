
# ОТЧЕТ ПО ДОМАШНЕМУ ЗАДАНИЮ

## 1. Описание данных
**Датасет:** Geo Reviews Dataset 2023
- **Размер исходных данных:** 93278 отзывов
- **После фильтрации нейтральных отзывов:** 93278 отзывов
- **После балансировки классов:** 93278 отзывов (поровну позитивных и негативных)
- **Целевая переменная:** sentiment (0 - негативный, 1 - позитивный)

## 2. Предобработка
Была реализована комплексная предобработка текста:
- Приведение к нижнему регистру
- Удаление HTML-тегов и URL-адресов
- Удаление специальных символов и пунктуации
- Токенизация и удаление стоп-слов
- Лемматизация для русского языка
- Фильтрация по длине слова (≥2 символа)

**Результат предобработки:**
- Средняя длина текста до обработки: 60.0 слов
- После обработки: 39.8 слов
- Уменьшение размера на 33.6%

## 3. Результаты моделей

### Сравнительные метрики:

| Модель | Accuracy | Precision | Recall | F1-score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| TF-IDF + LogisticRegression | 0.9455 | 0.9472 | 0.9437 | 0.9454 | 0.9819 |
| Word2Vec + LogisticRegression | 0.9387 | 0.9469 | 0.9295 | 0.9403 | 0.9787 |
| FastText + LogisticRegression | 0.9391 | 0.9465 | 0.9308 | 0.9386 | 0.9803 |

### Лучшая модель: TF-IDF + LogisticRegression
- **F1-score:** 0.9454
- **Accuracy:** 0.9455
- **ROC-AUC:** 0.9819

## 4. Сравнительный анализ

### TF-IDF + LogisticRegression
**Преимущества:**
- Наивысшее качество среди всех методов
- Хорошая интерпретируемость (можно анализировать важность слов)
- Быстрое обучение и предсказание
- Эффективно для коротких текстов

**Недостатки:**
- Не учитывает семантические отношения между словами
- Проблемы с OOV-словами (словами вне словаря)
- Высокая размерность признакового пространства

### Word2Vec + LogisticRegression  
**Преимущества:**
- Учитывает семантические отношения между словами
- Более низкая размерность признаков (100-200 features)
- Хорошо работает с синонимами

**Недостатки:**
- Не обрабатывает OOV-слова
- Требует больших вычислительных ресурсов для обучения
- Качество зависит от размера корпуса

### FastText + LogisticRegression
**Преимущества:**
- Обрабатывает OOV-слова через n-grams
- Хорошо работает с опечатками и морфологическими вариациями
- Эффективен для слов с общими морфемами

**Недостатки:**
- Немного уступает по качеству TF-IDF
- Больший размер модели из-за n-grams
- Сложнее в интерпретации

## 5. Анализ ошибок

**Типичные случаи ошибок всех моделей:**
1. **Сложные конструкции** с противительными союзами ("но", "однако", "хотя")
2. **Нейтральный язык** ("нормально", "средне", "приемлемо")
3. **Короткие тексты** (<5 слов) с недостаточным контекстом
4. **Условные конструкции** ("бы", "может", "возможно")
5. **Финансовые аспекты**, где мнение может быть неоднозначным

## 6. Выводы и рекомендации

1. **TF-IDF показал наилучшие результаты** для данной задачи анализа сентимента, что объясняется тем, что ключевые слова (такие как "отличный", "ужасный") являются сильными индикаторами sentiment и хорошо захватываются TF-IDF.

2. **Word2Vec и FastText** показали схожие результаты, но немного уступают TF-IDF, что может быть связано с относительно небольшим размером датасета для обучения качественных эмбеддингов.

3. **FastText демонстрирует преимущество** в обработке OOV-слов и морфологических вариаций, что особенно важно для русского языка с его богатой морфологией.
